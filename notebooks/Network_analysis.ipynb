{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network...\n",
      "\n",
      "Network Statistics:\n",
      "--------------------------------------------------\n",
      "\n",
      "Mainstream Media Layer:\n",
      "Nodes: 180\n",
      "Edges: 95\n",
      "Average Degree: 1.06\n",
      "\n",
      "We Media Layer:\n",
      "Nodes: 3246\n",
      "Edges: 3296\n",
      "Average Degree: 2.03\n",
      "\n",
      "Public Layer:\n",
      "Nodes: 2442\n",
      "Edges: 2376\n",
      "Average Degree: 1.95\n",
      "\n",
      "Interlayer Connections: 1106\n"
     ]
    }
   ],
   "source": [
    "from src.plot_multilayernetwork import *\n",
    "from src.modules import *\n",
    "import joblib\n",
    "print(\"Loading network...\")\n",
    "network = joblib.load('networks/simple_all_new.pkl')\n",
    "# 修改采样参数, 我们在这里保证不存在孤立节点\n",
    "layers, interlayer_edges = prepare_sampled_network(\n",
    "    network,\n",
    "    w_media_ratio=1.0,  # 增加自媒体采样比例\n",
    "    o_people_ratio=1.0,  # 增加普通用户采样比例\n",
    "    min_degree=1,       # 降低最小度数要求\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "from scipy.optimize import curve_fit\n",
    "import community.community_louvain as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_network_structure(layers, interlayer_edges):\n",
    "    \"\"\"Analyze structural features of multilayer networks with enhanced metrics\"\"\"\n",
    "    layer_names = ['Mainstream Media', 'We Media', 'Public']\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Layer-specific analysis\n",
    "    for i, (layer, name) in enumerate(zip(layers, layer_names)):\n",
    "        print(f\"\\n{name} Layer Analysis:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        metrics = {}\n",
    "        n_nodes = layer.number_of_nodes()\n",
    "        n_edges = layer.number_of_edges()\n",
    "        \n",
    "        # Basic topology\n",
    "        print(f\"Basic Metrics:\")\n",
    "        print(f\"- Nodes: {n_nodes}\")\n",
    "        print(f\"- Edges: {n_edges}\")\n",
    "        print(f\"- Density: {nx.density(layer):.4f}\")\n",
    "        \n",
    "        # Degree distribution analysis\n",
    "        degrees = [d for n, d in layer.degree()]\n",
    "        if len(degrees) > 5:\n",
    "            degree_metrics = fit_truncated_powerlaw(degrees)\n",
    "            print(f\"\\nDegree Distribution Analysis:\")\n",
    "            if 'error' not in degree_metrics:\n",
    "                print(f\"- Truncated Power-law α: {degree_metrics['alpha']:.3f}\")\n",
    "                print(f\"- Exponential cutoff λ: {degree_metrics['lambda']:.3f}\")\n",
    "                print(f\"- KS statistic: {degree_metrics['ks_statistic']:.3f}\")\n",
    "                print(f\"- p-value: {degree_metrics['p_value']:.3f}\")\n",
    "                print(f\"- Mean degree: {degree_metrics['mean_degree']:.3f}\")\n",
    "                print(f\"- Std degree: {degree_metrics['std_degree']:.3f}\")\n",
    "            else:\n",
    "                print(f\"- Fitting failed: {degree_metrics['error']}\")\n",
    "                print(f\"- Mean degree: {degree_metrics['mean_degree']:.3f}\")\n",
    "                print(f\"- Std degree: {degree_metrics['std_degree']:.3f}\")\n",
    "            metrics['degree_dist'] = degree_metrics\n",
    "        \n",
    "        # Community structure\n",
    "        if n_nodes > 0:\n",
    "            community_metrics = analyze_communities(layer)\n",
    "            print(f\"\\nCommunity Analysis:\")\n",
    "            print(f\"- Modularity: {community_metrics['modularity']:.3f}\")\n",
    "            print(f\"- Number of communities: {community_metrics['num_communities']}\")\n",
    "            metrics['community'] = community_metrics\n",
    "        \n",
    "        # Network robustness\n",
    "        robustness_metrics = analyze_network_robustness(layer)\n",
    "        print(f\"\\nRobustness Analysis:\")\n",
    "        print(f\"- Robustness score: {robustness_metrics['robustness_score']:.3f}\")\n",
    "        metrics['robustness'] = robustness_metrics\n",
    "        \n",
    "        results[name] = metrics\n",
    "    \n",
    "    # 2. Interlayer analysis\n",
    "    print(\"\\nInterlayer Connection Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    layer_connections = defaultdict(int)\n",
    "    for l1, n1, l2, n2 in interlayer_edges:\n",
    "        layer_connections[(l1, l2)] += 1\n",
    "    \n",
    "    total_interlayer = len(interlayer_edges)\n",
    "    for (l1, l2), count in layer_connections.items():\n",
    "        percentage = (count/total_interlayer*100) if total_interlayer > 0 else 0\n",
    "        print(f\"{layer_names[l1]} -> {layer_names[l2]}: {count} connections ({percentage:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def fit_truncated_powerlaw(degrees):\n",
    "    \"\"\"Improved power-law fitting with adaptive boundaries\"\"\"\n",
    "    degrees = np.array(degrees)\n",
    "    counts = Counter(degrees)\n",
    "    x = np.array(sorted(counts.keys()))\n",
    "    y = np.array([counts[k]/len(degrees) for k in x])\n",
    "    \n",
    "    # 根据数据特征自适应设置边界\n",
    "    max_alpha = 6.0 if len(degrees) > 1000 else 3.0\n",
    "    bounds = ([1.5, 0.001], [max_alpha, 1.0])\n",
    "    \n",
    "    def truncated_powerlaw(x, alpha, lambda_):\n",
    "        valid_x = np.maximum(x, 1e-10)\n",
    "        return valid_x**(-alpha) * np.exp(-lambda_ * valid_x)\n",
    "    \n",
    "    try:\n",
    "        popt, pcov = curve_fit(truncated_powerlaw, x, y, \n",
    "                             p0=[2.5, 0.1],\n",
    "                             bounds=bounds,\n",
    "                             maxfev=5000)\n",
    "        \n",
    "        # 计算拟合优度和KS检验\n",
    "        y_fit = truncated_powerlaw(x, *popt)\n",
    "        from scipy import stats\n",
    "        ks_statistic, p_value = stats.ks_2samp(y, y_fit)\n",
    "        \n",
    "        return {\n",
    "            'alpha': popt[0],\n",
    "            'lambda': popt[1],\n",
    "            'ks_statistic': ks_statistic,\n",
    "            'p_value': p_value,\n",
    "            'mean_degree': np.mean(degrees),\n",
    "            'std_degree': np.std(degrees),\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'y_fit': y_fit\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'mean_degree': np.mean(degrees),\n",
    "            'std_degree': np.std(degrees),\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def analyze_communities(G):\n",
    "    \"\"\"Analyze community structure using Louvain method\"\"\"\n",
    "    communities = community_louvain.best_partition(G)\n",
    "    modularity = community_louvain.modularity(communities, G)\n",
    "    \n",
    "    return {\n",
    "        'modularity': modularity,\n",
    "        'num_communities': len(set(communities.values())),\n",
    "        'community_sizes': dict(Counter(communities.values())),\n",
    "        'node_communities': communities\n",
    "    }\n",
    "\n",
    "def analyze_network_robustness(G):\n",
    "    \"\"\"Analyze network robustness through percolation analysis\"\"\"\n",
    "    gcc_sizes = []\n",
    "    nodes = list(G.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "    \n",
    "    for i in range(10):\n",
    "        remove_frac = i/10\n",
    "        n_remove = int(remove_frac * n_nodes)\n",
    "        \n",
    "        G_temp = G.copy()\n",
    "        removed = random.sample(nodes, n_remove)\n",
    "        G_temp.remove_nodes_from(removed)\n",
    "        \n",
    "        if G_temp.number_of_nodes() > 0:\n",
    "            gcc_size = len(max(nx.connected_components(G_temp), key=len))\n",
    "            gcc_sizes.append(gcc_size/n_nodes)\n",
    "        else:\n",
    "            gcc_sizes.append(0)\n",
    "    \n",
    "    return {\n",
    "        'percolation_curve': gcc_sizes,\n",
    "        'robustness_score': np.trapz(gcc_sizes)/10\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mainstream Media Layer Analysis:\n",
      "--------------------------------------------------\n",
      "Basic Metrics:\n",
      "- Nodes: 180\n",
      "- Edges: 95\n",
      "- Density: 0.0059\n",
      "\n",
      "Degree Distribution Analysis:\n",
      "- Truncated Power-law α: 1.500\n",
      "- Exponential cutoff λ: 0.088\n",
      "- KS statistic: 0.429\n",
      "- p-value: 0.575\n",
      "- Mean degree: 1.056\n",
      "- Std degree: 2.699\n",
      "\n",
      "Community Analysis:\n",
      "- Modularity: 0.829\n",
      "- Number of communities: 89\n",
      "\n",
      "Robustness Analysis:\n",
      "- Robustness score: 0.051\n",
      "\n",
      "We Media Layer Analysis:\n",
      "--------------------------------------------------\n",
      "Basic Metrics:\n",
      "- Nodes: 3246\n",
      "- Edges: 3296\n",
      "- Density: 0.0006\n",
      "\n",
      "Degree Distribution Analysis:\n",
      "- Truncated Power-law α: 5.351\n",
      "- Exponential cutoff λ: 0.033\n",
      "- KS statistic: 0.733\n",
      "- p-value: 0.000\n",
      "- Mean degree: 2.031\n",
      "- Std degree: 47.824\n",
      "\n",
      "Community Analysis:\n",
      "- Modularity: 0.311\n",
      "- Number of communities: 42\n",
      "\n",
      "Robustness Analysis:\n",
      "- Robustness score: 0.406\n",
      "\n",
      "Public Layer Analysis:\n",
      "--------------------------------------------------\n",
      "Basic Metrics:\n",
      "- Nodes: 2442\n",
      "- Edges: 2376\n",
      "- Density: 0.0008\n",
      "\n",
      "Degree Distribution Analysis:\n",
      "- Truncated Power-law α: 4.694\n",
      "- Exponential cutoff λ: 0.056\n",
      "- KS statistic: 0.800\n",
      "- p-value: 0.000\n",
      "- Mean degree: 1.946\n",
      "- Std degree: 34.193\n",
      "\n",
      "Community Analysis:\n",
      "- Modularity: 0.488\n",
      "- Number of communities: 144\n",
      "\n",
      "Robustness Analysis:\n",
      "- Robustness score: 0.254\n",
      "\n",
      "Interlayer Connection Analysis:\n",
      "--------------------------------------------------\n",
      "We Media -> Mainstream Media: 8 connections (0.7%)\n",
      "Public -> Mainstream Media: 15 connections (1.4%)\n",
      "Public -> We Media: 530 connections (47.9%)\n",
      "Mainstream Media -> We Media: 8 connections (0.7%)\n",
      "We Media -> Public: 530 connections (47.9%)\n",
      "Mainstream Media -> Public: 15 connections (1.4%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze networks\n",
    "results = analyze_network_structure(layers, interlayer_edges)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ordinary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
